# =====================================================================
# Image Engine - ComfyUI API ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ì—”ì§„ (Worker ì „ìš©)
# =====================================================================
# PC2 Workerì—ì„œ ì‹¤í–‰ë˜ëŠ” ì´ë¯¸ì§€ ìƒì„± ì—”ì§„
# - ComfyUI ì‚¬ì´ë“œì¹´ ì»¨í…Œì´ë„ˆì™€ HTTP/WebSocket í†µì‹ 
# - SD 3.5 Medium GGUF ëª¨ë¸ ì‚¬ìš© (8GB VRAM ìµœì í™”)
# - ë²ˆì—­ì€ PC1(Backend)ì—ì„œ ì²˜ë¦¬ í›„ ì˜ì–´ í”„ë¡¬í”„íŠ¸ ì „ë‹¬ë°›ìŒ
# =====================================================================

import os
import json
import uuid
import time
import requests
from pathlib import Path
from typing import Optional, Callable

# WebSocketì€ ì„ íƒì  ì˜ì¡´ì„± (ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ í´ë§ ë°©ì‹ ì‚¬ìš©)
try:
    import websocket
    WEBSOCKET_AVAILABLE = True
except ImportError:
    WEBSOCKET_AVAILABLE = False
    print("âš ï¸ [ImageEngine] websocket-client ë¯¸ì„¤ì¹˜, í´ë§ ë°©ì‹ ì‚¬ìš©")


# =====================================================================
# ì„¤ì •
# =====================================================================
COMFYUI_HOST = os.environ.get("COMFYUI_HOST", "comfyui")
COMFYUI_PORT = os.environ.get("COMFYUI_PORT", "8188")
COMFYUI_BASE_URL = f"http://{COMFYUI_HOST}:{COMFYUI_PORT}"

# ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ê²½ë¡œ
WORKFLOW_DIR = Path(__file__).parent / "workflows"
DEFAULT_WORKFLOW = "sd35_medium_gguf.json"

# ì¶œë ¥ í´ë” (ComfyUIì™€ ê³µìœ )
OUTPUT_DIR = Path("/ai_models/image/output")

# ì—°ê²° ì¬ì‹œë„ ì„¤ì •
MAX_RETRIES = 30
RETRY_DELAY = 2  # ì´ˆ


class ImageEngine:
    """
    ComfyUI API ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ì—”ì§„ í´ë˜ìŠ¤

    ComfyUI ì»¨í…Œì´ë„ˆì™€ HTTP/WebSocketìœ¼ë¡œ í†µì‹ í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ëŠ” ComfyUIê°€ ë‹´ë‹¹í•©ë‹ˆë‹¤.

    Attributes:
        workflow_template (dict): ComfyUI ì›Œí¬í”Œë¡œìš° JSON í…œí”Œë¦¿
        client_id (str): WebSocket í´ë¼ì´ì–¸íŠ¸ ì‹ë³„ì
    """

    def __init__(self):
        self.workflow_template = None
        self.client_id = str(uuid.uuid4())
        self._comfyui_ready = False

    def _load_workflow_template(self, workflow_name: str = DEFAULT_WORKFLOW) -> dict:
        """ì›Œí¬í”Œë¡œìš° JSON í…œí”Œë¦¿ ë¡œë“œ"""
        workflow_path = WORKFLOW_DIR / workflow_name
        if not workflow_path.exists():
            raise FileNotFoundError(f"ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {workflow_path}")

        with open(workflow_path, "r", encoding="utf-8") as f:
            return json.load(f)

    def _get_vram_stats(self) -> dict:
        """ComfyUIì—ì„œ GPU/VRAM ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            response = requests.get(f"{COMFYUI_BASE_URL}/system_stats", timeout=5)
            if response.status_code == 200:
                stats = response.json()
                devices = stats.get("devices", [])
                if devices:
                    gpu = devices[0]
                    vram_total = gpu.get("vram_total", 0)
                    vram_free = gpu.get("vram_free", 0)
                    vram_used = vram_total - vram_free
                    return {
                        "name": gpu.get("name", "Unknown"),
                        "vram_total_gb": round(vram_total / (1024**3), 2),
                        "vram_used_gb": round(vram_used / (1024**3), 2),
                        "vram_free_gb": round(vram_free / (1024**3), 2),
                        "vram_percent": round((vram_used / vram_total) * 100, 1) if vram_total > 0 else 0
                    }
        except Exception as e:
            print(f"âš ï¸ [ImageEngine] VRAM ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

    def _log_vram_usage(self, phase: str):
        """VRAM ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        stats = self._get_vram_stats()
        if stats:
            print(f"ğŸ“Š [VRAM] {phase}")
            print(f"   - GPU: {stats['name']}")
            print(f"   - ì‚¬ìš©ëŸ‰: {stats['vram_used_gb']}GB / {stats['vram_total_gb']}GB ({stats['vram_percent']}%)")
            print(f"   - ì—¬ìœ : {stats['vram_free_gb']}GB")

    def _wait_for_comfyui(self) -> bool:
        """ComfyUI ì„œë²„ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        if self._comfyui_ready:
            return True

        print(f"ğŸ”„ [ImageEngine] ComfyUI ì„œë²„ ëŒ€ê¸° ì¤‘... ({COMFYUI_BASE_URL})")

        for attempt in range(MAX_RETRIES):
            try:
                response = requests.get(f"{COMFYUI_BASE_URL}/system_stats", timeout=5)
                if response.status_code == 200:
                    print(f"âœ… [ImageEngine] ComfyUI ì„œë²„ ì—°ê²° ì„±ê³µ!")
                    self._comfyui_ready = True
                    return True
            except requests.exceptions.RequestException:
                pass

            print(f"   - ì¬ì‹œë„ {attempt + 1}/{MAX_RETRIES}...")
            time.sleep(RETRY_DELAY)

        print(f"âŒ [ImageEngine] ComfyUI ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
        return False

    def load_model(self):
        """
        ëª¨ë¸ ë¡œë”© (ComfyUIì—ì„œëŠ” ìë™ ê´€ë¦¬ë¨)

        ì´ ë©”ì„œë“œëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ì§€ë§Œ,
        ì‹¤ì œ ëª¨ë¸ ë¡œë”©ì€ ComfyUIê°€ ì²« ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        print("ğŸš€ [ImageEngine] ComfyUI ëª¨ë“œ - ëª¨ë¸ì€ ì²« ìš”ì²­ ì‹œ ìë™ ë¡œë”©ë©ë‹ˆë‹¤.")

        # ComfyUI ì„œë²„ ì—°ê²° í™•ì¸
        if not self._wait_for_comfyui():
            raise ConnectionError("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë¡œë“œ
        if self.workflow_template is None:
            self.workflow_template = self._load_workflow_template()
            print(f"âœ… [ImageEngine] ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë¡œë“œ ì™„ë£Œ")

    def is_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸ (ComfyUI ì—°ê²° ìƒíƒœ)"""
        return self._comfyui_ready

    def unload_model(self):
        """
        ëª¨ë¸ ì–¸ë¡œë“œ (ComfyUIì—ì„œëŠ” ë³„ë„ ì‘ì—… ë¶ˆí•„ìš”)

        ComfyUIê°€ ìì²´ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
        í•„ìš”ì‹œ ComfyUIì˜ /free ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        print("ğŸ”„ [ImageEngine] ComfyUI ëª¨ë“œ - ë©”ëª¨ë¦¬ëŠ” ComfyUIê°€ ìë™ ê´€ë¦¬í•©ë‹ˆë‹¤.")

        # ì„ íƒì : ComfyUI ë©”ëª¨ë¦¬ í•´ì œ ìš”ì²­
        try:
            requests.post(f"{COMFYUI_BASE_URL}/free", json={"free_memory": True}, timeout=10)
            print("âœ… [ImageEngine] ComfyUI ë©”ëª¨ë¦¬ í•´ì œ ìš”ì²­ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ [ImageEngine] ë©”ëª¨ë¦¬ í•´ì œ ìš”ì²­ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    def _apply_style_prompt(self, prompt: str, style: str) -> tuple:
        """ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìˆ˜ì‹ì–´ ì¶”ê°€ ë° ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜

        SD 3.5 Mediumì€ ìì—°ì–´ ê¸°ë°˜ T5 ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ,
        íƒœê·¸ ë‚˜ì—´ë³´ë‹¤ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥í˜• í”„ë¡¬í”„íŠ¸ê°€ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.
        """
        style_config = {
            # === SD 3.5 ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¹í™” í”„ë¦¬ì…‹ ===
            "corporate": {
                "positive": "professional commercial photography, authentic business atmosphere, shot on 35mm lens, soft studio lighting, depth of field, modern office environment, high quality, 4k",
                "negative": "anime, cartoon, illustration, low quality, blurry, deformed, watermark, text overlay"
            },
            "product": {
                "positive": "professional product photography, studio lighting, clean white background, 8k uhd, commercial advertisement style, sharp details, centered composition",
                "negative": "noisy, grainy, low resolution, messy background, dark, shadows, cluttered"
            },
            "typography": {
                "positive": "high quality poster design, clear typography, cinematic lighting, vibrant colors, professional graphic design, sharp text rendering",
                "negative": "spelling mistakes, blurry text, messy lines, low resolution, pixelated"
            },
            # === ê¸°ì¡´ ìŠ¤íƒ€ì¼ (SD 3.5 ìµœì í™”) ===
            "realistic": {
                "positive": "photorealistic photograph, highly detailed, professional photography, natural lighting, 8k uhd, sharp focus, authentic look",
                "negative": "cartoon, anime, illustration, painting, drawing, low quality, blurry, deformed, artificial"
            },
            "anime": {
                "positive": "anime style artwork, vibrant colors, cel shading, studio ghibli inspired, manga art, detailed illustration",
                "negative": "photorealistic, photo, 3d render, low quality, blurry, deformed"
            },
            "cartoon": {
                "positive": "cartoon style illustration, bold outlines, flat colors, playful design, disney style, clean lines",
                "negative": "photorealistic, photo, anime, low quality, blurry, deformed"
            }
        }

        config = style_config.get(style, style_config["realistic"])
        positive = f"{prompt}, {config['positive']}"
        negative = config["negative"]

        return positive, negative

    def _parse_size(self, size: str) -> tuple:
        """í¬ê¸° ë¬¸ìì—´ì„ width, height íŠœí”Œë¡œ íŒŒì‹±"""
        try:
            width, height = map(int, size.split("x"))
            # SD 3.5ëŠ” 1024x1024ê°€ ê¸°ë³¸, 64ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
            width = max(512, min(2048, (width // 64) * 64))
            height = max(512, min(2048, (height // 64) * 64))
            return width, height
        except:
            return 1024, 1024  # SD 3.5 ê¸°ë³¸ í•´ìƒë„

    def _inject_parameters(
        self,
        workflow: dict,
        positive_prompt: str,
        negative_prompt: str,
        width: int,
        height: int,
        seed: int,
        steps: int,
        cfg: float,
        output_prefix: str
    ) -> dict:
        """ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ì— íŒŒë¼ë¯¸í„° ì£¼ì…"""
        # ê¹Šì€ ë³µì‚¬
        workflow_copy = json.loads(json.dumps(workflow))
        prompt_data = workflow_copy.get("prompt", workflow_copy)

        # ê° ë…¸ë“œì˜ ì…ë ¥ê°’ì„ ë¬¸ìì—´ ì¹˜í™˜
        workflow_str = json.dumps(prompt_data)

        # í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ JSON ì•ˆì „í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„ (ë”°ì˜´í‘œ, ë°±ìŠ¬ë˜ì‹œ ë“± ì²˜ë¦¬)
        def escape_for_json(s: str) -> str:
            # json.dumpsë¡œ ì´ìŠ¤ì¼€ì´í”„ í›„ ì•ë’¤ ë”°ì˜´í‘œ ì œê±°
            return json.dumps(s)[1:-1]

        replacements = {
            "{{POSITIVE_PROMPT}}": escape_for_json(positive_prompt),
            "{{NEGATIVE_PROMPT}}": escape_for_json(negative_prompt),
            "{{WIDTH}}": str(width),
            "{{HEIGHT}}": str(height),
            "{{SEED}}": str(seed),
            "{{STEPS}}": str(steps),
            "{{CFG}}": str(cfg),
            "{{OUTPUT_PREFIX}}": output_prefix
        }

        for placeholder, value in replacements.items():
            workflow_str = workflow_str.replace(placeholder, value)

        return json.loads(workflow_str)

    def _queue_prompt(self, prompt: dict) -> str:
        """ComfyUIì— í”„ë¡¬í”„íŠ¸ í ìš”ì²­"""
        payload = {
            "prompt": prompt,
            "client_id": self.client_id
        }

        response = requests.post(
            f"{COMFYUI_BASE_URL}/prompt",
            json=payload,
            timeout=30
        )
        response.raise_for_status()

        result = response.json()
        prompt_id = result.get("prompt_id")

        if not prompt_id:
            raise RuntimeError(f"í”„ë¡¬í”„íŠ¸ IDë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {result}")

        return prompt_id

    def _wait_for_completion_polling(self, prompt_id: str, timeout: int = 300) -> bool:
        """í´ë§ ë°©ì‹ìœ¼ë¡œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°"""
        start_time = time.time()

        while time.time() - start_time < timeout:
            try:
                response = requests.get(f"{COMFYUI_BASE_URL}/history/{prompt_id}", timeout=10)
                if response.status_code == 200:
                    history = response.json()
                    if prompt_id in history:
                        status = history[prompt_id].get("status", {})
                        if status.get("completed", False):
                            return True
                        if status.get("status_str") == "error":
                            raise RuntimeError(f"ComfyUI ì‘ì—… ì‹¤íŒ¨: {history[prompt_id]}")
            except requests.exceptions.RequestException:
                pass

            time.sleep(1)

        raise TimeoutError(f"ì´ë¯¸ì§€ ìƒì„± íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")

    def _wait_for_completion_websocket(self, prompt_id: str, timeout: int = 300) -> bool:
        """WebSocket ë°©ì‹ìœ¼ë¡œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°"""
        ws_url = f"ws://{COMFYUI_HOST}:{COMFYUI_PORT}/ws?clientId={self.client_id}"

        ws = websocket.create_connection(ws_url, timeout=timeout)
        try:
            start_time = time.time()

            while time.time() - start_time < timeout:
                result = ws.recv()
                if result:
                    message = json.loads(result)
                    msg_type = message.get("type")

                    if msg_type == "executing":
                        data = message.get("data", {})
                        if data.get("prompt_id") == prompt_id:
                            if data.get("node") is None:
                                # ëª¨ë“  ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ
                                return True

                    elif msg_type == "execution_error":
                        raise RuntimeError(f"ComfyUI ì‹¤í–‰ ì˜¤ë¥˜: {message}")

                    elif msg_type == "progress":
                        data = message.get("data", {})
                        value = data.get("value", 0)
                        max_val = data.get("max", 1)
                        print(f"   ğŸ“Š ì§„í–‰ë¥ : {value}/{max_val}")

        finally:
            ws.close()

        raise TimeoutError(f"ì´ë¯¸ì§€ ìƒì„± íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")

    def _get_output_images(self, prompt_id: str) -> list:
        """ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì¡°íšŒ"""
        response = requests.get(f"{COMFYUI_BASE_URL}/history/{prompt_id}", timeout=10)
        response.raise_for_status()

        history = response.json()
        if prompt_id not in history:
            return []

        outputs = history[prompt_id].get("outputs", {})
        images = []

        for node_id, node_output in outputs.items():
            if "images" in node_output:
                for img_info in node_output["images"]:
                    filename = img_info.get("filename")
                    subfolder = img_info.get("subfolder", "")
                    if filename:
                        if subfolder:
                            images.append(OUTPUT_DIR / subfolder / filename)
                        else:
                            images.append(OUTPUT_DIR / filename)

        return images

    def generate(
        self,
        prompt: str,
        style: str = "realistic",
        size: str = "1024x1024",
        num_inference_steps: int = 28,
        guidance_scale: float = 4.5,
        seed: Optional[int] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> bytes:
        """
        í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±

        Args:
            prompt (str): ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì˜ì–´, PC1ì—ì„œ ë²ˆì—­ë¨)
            style (str): ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼
            size (str): ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸: 1024x1024)
            num_inference_steps (int): ì¶”ë¡  ë‹¨ê³„ ìˆ˜ (SD 3.5 ê¶Œì¥: 28)
            guidance_scale (float): CFG ìŠ¤ì¼€ì¼ (SD 3.5 ê¶Œì¥: 4.5)
            seed (Optional[int]): ëœë¤ ì‹œë“œ
            progress_callback: ì§„í–‰ë¥  ì½œë°± (ë¯¸ì‚¬ìš©, í˜¸í™˜ì„± ìœ ì§€)

        Returns:
            bytes: PNG í˜•ì‹ì˜ ì´ë¯¸ì§€ ë°”ì´íŠ¸
        """
        start_time = time.time()

        try:
            # 1. ComfyUI ì—°ê²° í™•ì¸
            if not self._wait_for_comfyui():
                raise ConnectionError("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # 2. ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë¡œë“œ
            if self.workflow_template is None:
                self.workflow_template = self._load_workflow_template()

            # 3. íŒŒë¼ë¯¸í„° ì¤€ë¹„
            positive_prompt, negative_prompt = self._apply_style_prompt(prompt, style)
            width, height = self._parse_size(size)
            actual_seed = seed if seed is not None else int(time.time() * 1000) % (2**32)
            output_prefix = f"dot_{uuid.uuid4().hex[:8]}"

            print(f"ğŸ¨ [ImageEngine] ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (ComfyUI)")
            print(f"   - í”„ë¡¬í”„íŠ¸: {prompt[:50]}...")
            print(f"   - ìŠ¤íƒ€ì¼: {style}")
            print(f"   - í¬ê¸°: {width}x{height}")
            print(f"   - ìŠ¤í…: {num_inference_steps}")
            print(f"   - CFG: {guidance_scale}")
            print(f"   - ì‹œë“œ: {actual_seed}")

            # VRAM ì‚¬ìš©ëŸ‰ ë¡œê¹… (ìƒì„± ì „)
            self._log_vram_usage("ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ ì „")

            # 4. ì›Œí¬í”Œë¡œìš°ì— íŒŒë¼ë¯¸í„° ì£¼ì…
            workflow = self._inject_parameters(
                self.workflow_template,
                positive_prompt,
                negative_prompt,
                width,
                height,
                actual_seed,
                num_inference_steps,
                guidance_scale,
                output_prefix
            )

            # 5. ComfyUIì— ì‘ì—… ìš”ì²­
            print(f"ğŸ“¤ [ImageEngine] ComfyUIì— ì‘ì—… ìš”ì²­ ì¤‘...")
            prompt_id = self._queue_prompt(workflow)
            print(f"   - Prompt ID: {prompt_id}")

            # 6. ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            print(f"â³ [ImageEngine] ì´ë¯¸ì§€ ìƒì„± ëŒ€ê¸° ì¤‘...")
            if WEBSOCKET_AVAILABLE:
                self._wait_for_completion_websocket(prompt_id)
            else:
                self._wait_for_completion_polling(prompt_id)

            # 7. ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ì¡°íšŒ
            output_images = self._get_output_images(prompt_id)
            if not output_images:
                raise RuntimeError("ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # 8. ì²« ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
            image_path = output_images[0]
            print(f"   - ì¶œë ¥ íŒŒì¼: {image_path}")

            # íŒŒì¼ì´ ìƒì„±ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
            for _ in range(10):
                if image_path.exists():
                    break
                time.sleep(0.5)

            if not image_path.exists():
                raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

            with open(image_path, "rb") as f:
                image_bytes = f.read()

            # ComfyUI ì„ì‹œ ì¶œë ¥ íŒŒì¼ ì‚­ì œ (PC1ì— HTTP ì „ì†¡ í›„ ìœ ì¼í•œ ì‚¬ë³¸ì´ ë¨)
            try:
                image_path.unlink()
                print(f"ğŸ—‘ï¸ [ImageEngine] ComfyUI ì„ì‹œ íŒŒì¼ ì‚­ì œ: {image_path.name}")
            except Exception:
                pass

            # VRAM ì‚¬ìš©ëŸ‰ ë¡œê¹… (ìƒì„± í›„)
            self._log_vram_usage("ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ í›„")

            total_time = time.time() - start_time
            print(f"âœ… [ImageEngine] ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            print(f"   - íŒŒì¼ í¬ê¸°: {len(image_bytes)} bytes")
            print(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")

            return image_bytes

        except Exception as e:
            # ComfyUI ì—°ê²° ì‹¤íŒ¨ ì‹œ ready ìƒíƒœ ë¦¬ì…‹ â†’ ë‹¤ìŒ ìš”ì²­ì—ì„œ ì¬ì—°ê²° ì‹œë„
            error_str = str(e).lower()
            if any(kw in error_str for kw in ['connection', 'resolve', 'refused', 'lost', 'timeout', 'disconnect']):
                self._comfyui_ready = False
                print(f"ğŸ”„ [ImageEngine] ComfyUI ì—°ê²° ìƒíƒœ ë¦¬ì…‹ (ë‹¤ìŒ ìš”ì²­ ì‹œ ì¬ì—°ê²°)")
            raise


# =====================================================================
# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
# =====================================================================
_image_engine_instance = None


def get_image_engine() -> ImageEngine:
    """ImageEngine ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _image_engine_instance
    if _image_engine_instance is None:
        _image_engine_instance = ImageEngine()
    return _image_engine_instance


def load_image_model():
    """ì´ë¯¸ì§€ ëª¨ë¸ ë¡œë”© (ComfyUI ì—°ê²° í™•ì¸)"""
    engine = get_image_engine()
    engine.load_model()


def unload_image_model():
    """ì´ë¯¸ì§€ ëª¨ë¸ ì–¸ë¡œë“œ (ComfyUI ë©”ëª¨ë¦¬ í•´ì œ ìš”ì²­)"""
    engine = get_image_engine()
    engine.unload_model()
